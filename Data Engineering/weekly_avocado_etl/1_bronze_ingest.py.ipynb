{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4bef2cd1-18aa-44fc-a788-55a66b170de3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ingest_bronze // NOT FOR S3 BUCKETS\n",
    "import yaml\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark.sql(\"use catalog bronze\")\n",
    "\n",
    "config_path = \"/Workspace/Users/clarkscoberly@gmail.com/config.yaml\"\n",
    "with open(config_path) as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS bronze\")\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS silver\")\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS gold\")\n",
    "\n",
    "S3 = config.get(\"s3_bucket\")\n",
    "BRONZE = config.get(\"bronze_path\", \"bronze/\")\n",
    "\n",
    "bronze_consumer = spark.read.option(\"header\", True).csv(\"/Volumes/landing/default/purchase/Tendo Exercise Data - consumer.csv\")\n",
    "bronze_purchase = spark.read.option(\"header\", True).csv(\"/Volumes/landing/default/purchase/Tendo Exercise Data - purchase.csv\")\n",
    "bronze_fertilizer = spark.read.option(\"header\", True).csv(\"/Volumes/landing/default/purchase/Tendo Exercise Data - fertilizer.csv\")\n",
    "bronze_avocado = spark.read.option(\"header\", True).csv(\"/Volumes/landing/default/purchase/Tendo Exercise Data - avocado.csv\")\n",
    "\n",
    "# Format for spaces in column names\n",
    "bronze_purchase = bronze_purchase.toDF(\n",
    "    *[c.replace(\" \", \"_\") for c in bronze_purchase.columns]\n",
    ")\n",
    "bronze_consumer = bronze_consumer.toDF(\n",
    "    *[c.replace(\" \", \"_\") for c in bronze_consumer.columns]\n",
    ")\n",
    "bronze_fertilizer = bronze_fertilizer.toDF(\n",
    "    *[c.replace(\" \", \"_\") for c in bronze_fertilizer.columns]\n",
    ")\n",
    "bronze_avocado = bronze_avocado.toDF(\n",
    "    *[c.replace(\" \", \"_\") for c in bronze_avocado.columns]\n",
    ")\n",
    "\n",
    "bronze_consumer.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"bronze.consumer\")\n",
    "bronze_purchase.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"bronze.purchase\")\n",
    "bronze_fertilizer.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"bronze.fertilizer\")\n",
    "bronze_avocado.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"bronze.avocado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6733a6fa-fbcb-4abf-b761-818a9edea16b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ingest_bronze_autoloader.py\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "import yaml\n",
    "\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS bronze\")\n",
    "\n",
    "# Load configuration\n",
    "config_path = \"/Workspace/Users/clarkscoberly@gmail.com/config.yaml\"\n",
    "with open(config_path) as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "S3_BUCKET = config[\"s3_bucket\"]\n",
    "BRONZE_PATH = config.get(\"bronze_path\", \"bronze/\")\n",
    "\n",
    "# AutoLoader options\n",
    "def autoload_delta(path, table_name):\n",
    "    df = (\n",
    "        spark.readStream\n",
    "        .format(\"cloudFiles\")\n",
    "        .option(\"cloudFiles.format\", \"csv\")\n",
    "        .option(\"header\", True)\n",
    "        .option(\"inferSchema\", True)\n",
    "        .load(path)\n",
    "    )\n",
    "    # Rename columns to remove spaces\n",
    "    df = df.toDF(*[c.replace(\" \", \"_\") for c in df.columns])\n",
    "    \n",
    "    (\n",
    "        df.writeStream\n",
    "        .format(\"delta\")\n",
    "        .outputMode(\"append\")\n",
    "        .option(\"checkpointLocation\", f\"{BRONZE_PATH}/{table_name}/_checkpoints\")\n",
    "        .toTable(f\"bronze.{table_name}\")\n",
    "    )\n",
    "\n",
    "# Paths in S3 (incremental ingest)\n",
    "autoload_delta(f\"{S3_BUCKET}/consumer/\", \"consumer\")\n",
    "autoload_delta(f\"{S3_BUCKET}/purchase/\", \"purchase\")\n",
    "autoload_delta(f\"{S3_BUCKET}/avocado/\", \"avocado\")\n",
    "autoload_delta(f\"{S3_BUCKET}/fertilizer/\", \"fertilizer\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1_bronze_ingest.py",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
